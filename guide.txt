


```py yt-skrapare/yt-skrapare.py
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
import time

def fetch_and_parse(url):
    response = requests.get(url)
    if response.status_code == 200:
        return BeautifulSoup(response.text, 'html.parser')
    return None

def extract_youtube_links(soup):
    youtube_links = []
    iframes = soup.find_all('iframe')
    for iframe in iframes:
        src = iframe.get('src')
        if src and 'youtube.com/embed/' in src:
            youtube_links.append(src)
    return youtube_links

def extract_links(soup, base_url):
    links = set()
    for a_tag in soup.find_all('a', href=True):
        href = a_tag['href']
        full_url = urljoin(base_url, href)
        if urlparse(full_url).netloc == urlparse(base_url).netloc:
            links.add(full_url)
    return links

def crawl_website(start_url, max_pages=5000):
    visited = set()
    to_visit = {start_url}
    youtube_data = []

    while to_visit and len(visited) < max_pages:
        url = to_visit.pop()
        if url in visited:
            continue

        print(f"Skrapar: {url}")
        soup = fetch_and_parse(url)
        if soup:
            visited.add(url)
            youtube_links = extract_youtube_links(soup)
            for link in youtube_links:
                youtube_data.append((url, link))
            new_links = extract_links(soup, start_url)
            to_visit.update(new_links - visited)

        time.sleep(1)

    return youtube_data

start_url = 'https://draj.se/'
youtube_data = crawl_website(start_url)

print("Hittade YouTube-klipp:")
for page, link in youtube_data:
    print(f"Sida: {page} \nYouTube-video: {link}\n")
```

vad gör den häer filen?

Den här Python-filen är en webbskrapa (web scraper) som är designad för att crawla en webbplats och hitta YouTube-videor inbäddade på sidorna. Här är en översikt av vad koden gör:

1. Den börjar med att besöka en startURL (i detta fall 'https://draj.se/').

2. För varje besökt sida:
   - Den hämtar sidans innehåll och analyserar HTML-strukturen.
   - Den letar efter iframe-element som innehåller YouTube-videor.
   - Den extraherar länkar till andra sidor på samma domän.

3. Den fortsätter att besöka nya sidor som den hittar, upp till ett maximalt antal sidor (5000 i detta fall).

4. För varje YouTube-video den hittar, sparar den URL:en till sidan där videon hittades och länken till YouTube-videon.

5. Den väntar 1 sekund mellan varje sidbesök för att inte överbelasta servern.

6. Till slut skriver den ut en lista över alla YouTube-videor den hittade, tillsammans med URL:erna till sidorna där de hittades.

Huvudfunktionerna inkluderar:
- `fetch_and_parse`: Hämtar och analyserar en webbsida.
- `extract_youtube_links`: Hittar YouTube-videolänkar på en sida.
- `extract_links`: Hittar andra interna länkar på sidan.
- `crawl_website`: Huvudfunktionen som styr crawling-processen.

Detta skript kan vara användbart för att hitta alla YouTube-videor som är inbäddade på en specifik webbplats, vilket kan vara användbart för innehållsanalys eller för att sammanställa en lista över videor som används på webbplatsen.

om jag vill kunna köra det här på vilken dator som helst, hur gör jag då utan att behöva installera massa bibliotek osv?

För att kunna köra detta skript på vilken dator som helst utan att behöva installera extra bibliotek, kan du använda Python's inbyggda `venv` (virtual environment) och skapa en fristående körbar fil. Här är stegen du kan följa:

1. Skapa en virtual environment:
   ```
   python -m venv yt-skrapare-env
   ```

2. Aktivera virtual environment:
   - På Windows: `yt-skrapare-env\Scripts\activate`
   - På macOS/Linux: `source yt-skrapare-env/bin/activate`

3. Installera nödvändiga bibliotek i denna miljö:
   ```
   pip install requests beautifulsoup4 pyinstaller
   ```

4. Använd PyInstaller för att skapa en fristående körbar fil:
   ```
   pyinstaller --onefile yt-skrapare.py
   ```

5. Den körbara filen kommer att skapas i en `dist`-mapp.

Nu har du en fristående körbar fil som du kan distribuera och köra på andra datorer utan att behöva installera Python eller några extra bibliotek.

För att göra det ännu enklare att använda, kan du:

1. Skapa en konfigurationsfil (t.ex. `config.txt`) där användaren kan ange start-URL:en.

2. Modifiera skriptet för att läsa denna konfigurationsfil:

```python
def read_config():
    with open('config.txt', 'r') as f:
        return f.read().strip()

start_url = read_config()
```

3. Skapa en enkel batch-fil (för Windows) eller shell-skript (för macOS/Linux) som kör programmet och sparar resultatet i en textfil:

För Windows (`run_skrapare.bat`):
```batch
@echo off
yt-skrapare.exe > resultat.txt
pause
```

För macOS/Linux (`run_skrapare.sh`):
```bash
#!/bin/bash
./yt-skrapare > resultat.txt
```

Med dessa steg får du en portabel lösning som kan köras på de flesta datorer utan ytterligare installation eller konfiguration.

kan du förklara det här steget mer, jag förstår inte: 2. Aktivera virtual environment:
   - På Windows: `yt-skrapare-env\Scripts\activate`
   - På macOS/Linux: `source yt-skrapare-env/bin/activate`

Absolut! Jag förstår att detta steg kan vara förvirrande, särskilt om man är ny till konceptet med virtuella miljöer. Låt mig förklara det mer detaljerat:

När du skapar en virtuell miljö (virtual environment) med `venv`, skapar Python en isolerad miljö på din dator. Denna miljö innehåller en egen kopia av Python och dess egna plats för att installera paket. Men för att använda denna miljö måste du "aktivera" den.

Att "aktivera" den virtuella miljön betyder att du tillfälligt ändrar din terminals eller kommandopromptens inställningar så att den använder Python-versionen och paketen i den virtuella miljön istället för de som är installerade globalt på din dator.

Här är hur du gör det steg för steg:

För Windows:
1. Öppna Kommandotolken (cmd) eller PowerShell.
2. Navigera till mappen där du skapade den virtuella miljön.
3. Skriv `yt-skrapare-env\Scripts\activate` och tryck Enter.
4. Du bör se `(yt-skrapare-env)` i början av din kommandorad, vilket indikerar att miljön är aktiverad.

För macOS/Linux:
1. Öppna Terminal.
2. Navigera till mappen där du skapade den virtuella miljön.
3. Skriv `source yt-skrapare-env/bin/activate` och tryck Enter.
4. Du bör se `(yt-skrapare-env)` i början av din kommandorad, vilket indikerar att miljön är aktiverad.

När miljön är aktiverad:
- Alla Python-kommandon du kör kommer att använda versionen i den virtuella miljön.
- Alla paket du installerar med `pip` kommer att installeras i denna isolerade miljö.

För att avaktivera miljön när du är klar, skriv bara `deactivate` i terminalen.

Denna process hjälper dig att hålla dina projekt isolerade från varandra och från ditt systems globala Python-installation, vilket förhindrar konflikter mellan olika versioner av paket.
